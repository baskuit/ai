abstraction: TODO
action: |
  A feasible operation on the [state](#state) ---  _i.e._, a move a [player](#player) can make at a
  stage in the [game](#game). "move" is ambiguous in Pokémon, as Pokémon have
  [moves](https://bulbapedia.bulbagarden.net/wiki/Move) and thus some of the game theoretical
  "moves" of a player in a Pokémon battle includes the action of literally using one of their
  Pokémon's moves. [Pokémon Showdown!](#PS) and [pkmn](#pkmn) instead use the term
  "choice"/"choices" instead of "action"/"actions", and
  [poke-sim](https://github.com/aed3/poke-sim/) refers to this as a
  "[decision](https://github.com/aed3/poke-sim/blob/main/DESIGN_SPEC.md#decision)" - all of these
  should be interchangeable, though using "move" to refer to an action/choice/decision should be
  avoided. Both player's choices considered together are called the [joint action]{.dfn}, and
  applying the join action to the battle state causes a [transition](#transition).
agent: |
  An intelligent agent ([IA]{.dfn}) is an entity that autonomously acts upon an environment to
  achieve its goals. In computer Chess the individual agents are usually referred to as "engines",
  but in competitive Pokémon artificial intelligence circles "agent" or "[bot](#bot)" is prefered as
  [engine](#engine) is used to refer to the piece code responsible for the simulation of core
  Pokémon battle mechanics.
Alpha-beta: |
  Alpha-beta pruning is a search algorithm that seeks to decrease the number of nodes that are
  evaluated by the [minimax](#minimax) algorithm in its search tree. When applied to a standard
  minimax tree, it returns the same move as minimax would, but [prunes](#pruning) away branches that
  cannot possibly influence the final decision. Alpha-beta has been shown to also work by
  [simultaneous move](#SM) games in [(Bošanský 2013)](/research#Bošanský:2013){.subtle} and
  [(Saffidine 2021)](/research#Saffidine:2021){.subtle}.
AlphaGo: |
  An influential artificial intelligence agent which achieved superhuman
  [Go](https://en.wikipedia.org/wiki/Go_(game)) performance using a combination of [Monte-carlo tree
  search](#MCTS) and [neural networks](#NN) [(Silver 2016)](/research#Silver:2016){.subtle}. Along
  with AlphaZero [(Silver 2017)](/research#Silver:2017){.subtle} and MuZero [(Silver
  2018)](/research#Silver:2018){.subtle}, the AlphaGo architecture serves as the modern foundation
  for many perfect information game-playing agents (_e.g._, [Lc0](#Lc0)).
anytime: |
  An anytime algorithm is an algorithm that can return a valid solution to a problem even if it is
  interrupted before it ends.
bandit: |
  The [multi-armed bandit problem]{.dfn} is a classic [reinforcement learning](#RL) problem that
  exemplifies the exploration--exploitation tradeoff dilemma. In the problem a fixed limited set of
  resources must be allocated between competing (alternative) choices in a way that maximizes their
  expected gain, when each choice's properties are only partially known at the time of allocation,
  and may become better understood as time passes or by allocating resources to the choice. In terms
  of competitive Pokémon AIs bandit problems arise when determining which parts of the [search tree
  to explore](#TBS), and "bandit" usually refers to the particular type of algorithm being used to
  solve the bandit problem (_e.g._, [UCB](#UCB) or [Exp3](#Exp3)).
Bayes' rule: TODO
Bayeselo: |
  [Bayesian Elo Rating](https://www.remi-coulom.fr/Bayesian-Elo/), a commonly used tool for
  estimating the [Elo](#Elo) rating based on matches between computerized agents.
belief: TODO
bimatrix game: |
  A [simultaneous game](#SM) for two players in which each player has a finite set of actions. Such
  a game can be fully described by two matrices, each describing the payoffs of one of the players.
binding: |
  Either refers to a [language binding]{.dfn}, the application programming interface that provides
  glue code specifically made to allow a programming language to use a foreign library or operating
  system service, or a [specific class of moves in Pokémon known as [binding
  moves]{.dfn}](https://bulbapedia.bulbagarden.net/wiki/Bound) which prevent their target from
  switching and cause damage for multiple turns (also known as "wrapping" or "partial-trapping"
  moves).
BoN: |
  Abbreviation for Best-of-$`N`, where $`N` refers to the number of games used to decide the winner
  of a set of battles between two players (usually 1 or 3, _e.g._, "BO3").
bot: |
  Slang term for [agent](#agent) derived from the word "robot". Alternatively, may be used to
  characterize the parts of the [client](#client) code responsible for connecting and communicating
  with the [server](#server) and distinguishing it from the core search/knowledge components of the
  agent.
branching factor: |
  The number of children at each node in a [game tree](#game-tree), the outdegree.
bucketing: |
  Also known as [data binning]{.dfn}, a generalization of rounding data where the original data that
  falls within a small interval ("bin"/"bucket") gets replaced by a value representative of that
  interval. This is a form of [abstraction](#abstraction), the canonical examples of bucketing in
  competitive Pokémon AI research are reducing the range of possible hit point values or shrinking
  the number of damage [rolls](#roll).
cartridge: |
  The game of Pokémon as it exists on the original Nintendo console hardware (due to the earliest
  [generations](#generation) of Pokémon being played on Game Boy ROM cartridges).
CFR: TODO CFR+, MC-CFR
chance: TODO chance node, Chance player, -Dchance
client: |
  Code that communicates with the game [engine](#engine) and enables a player to play the game. In
  the standard case of Pokémon the client only has a partial representation of one perspective of
  the actual battle state stored on the [server](#server). Clients connect to the server and
  communicate with the server via a [protocol](#protocol), and by default this protocol does not
  share hidden [information](#information).
conmeta: |
  A constructed [metagame](#metagame) where the artificially created rules have been arbitrarily
  tailored to simplify things for artificial intelligence agents, _e.g._, the [Shanai
  Cup](https://web.archive.org/web/20110706011535/http://pokemon-online.eu/forums/showthread.php?6273).
consolidation: TODO
contempt: |
  The contempt factor reflects the estimated superiority/inferiority of the program over its
  opponent. Programs incorporating contempt may choose to follow different strategies against
  opponents of varying perceived skill level.
damage calculator: TODO
damage coalition: TODO (action consolidation)
depth: |
  The depth of a node is the number of edges from the node to the [tree's](#game-tree) root node. A
  root node will have a depth of 0.
determinization: |
  The technique of sampling different perfect information states from the set of possibile imperfect
  information states so that methods for solving perfect information games can be applied to games
  with imperfect information.
drafting: |
  A component of certain Pokémon [variants](#variant) where players take turns choosing the Pokémon
  species which will form their pool of available choices during a later
  [team-building](#team-building) component.
driver: |
  Code which operates/controls the [engine](#engine), perhaps to provide additional features or to
  allow for integration within a broader application.
EBC: |
  [Endless Battle Clause](https://dex.pokemonshowdown.com/articles/battlerules), a rule that exists
  in [Smogon](#Smogon) [formats](#format) to guarantee that all battles will terminate in 1000 turns
  or fewer, while also seeking to curtail certain specific degenerate strategies.
EE: |
  Extreme equilbrium, a Nash equilibrium where for both players' mixed strategies cannot be
  described as convex combinations of other mixed strategies that form equilibria.
EEE: |
  Enumeration of extreme equilbria, a linear programming algorithm for determining all of the
  possible [Nash equilibrium](#NE) solutions in a [bimatrix game](#bimatrix-game).
EFG: |
  An [extensive-form game]{.dfn} is a specification of a [game](#game) allowing for the explicit
  representation of a number of key aspects, like the sequencing of players' possible moves, their
  choices at every [decision point](#turn), the (possibly imperfect) [information](#information)
  each player has about the other player's moves when they make a decision, and their
  [payoffs](#payoff) for all possible game outcomes. Extensive-form games also allow for the
  representation of incomplete information in the form of [chance events](#chance) modeled as "moves
  by nature". Alternatives to the extensive-form game respresentation is the [normal-form]{.dfn}
  representation that simply boils the game down to a payoff [matrix](#bimatrix-game), for the
  [FOSG](#FOSG) representation.
Elo: TODO
embedding: TODO
emulator: TODO
endgame: TODO
engine: |
  The core code responsible for implementing Pokémon battle mechanics. While multiple
  [engines](/concepts/engines) exist, without any other context the term "engine" may also refer
  specifically to the [pkmn](#pkmn) [engine](https://pkmn.cc/engine).
EPOké: |
  A [pkmn](#pkmn) [client](#client) library that parses [protocol](#protocol) and builds up a
  representation of the perceived battle state ([information set](#information-set)) using
  [inference](#inference).
Exp3: |
  Exponential-weight algorithm for Exploration and Exploitation, a [bandit](#bandit) algorithm
  commonly used in [tree bandit search](#TBS).
expectiminimax: TODO
exploitability: TODO ε-exploitability
extreme equilibria: TODO
format: TODO metagame
FOSG: |
  A [factored-observation stochastic game]{.dfn} TODO
FP: TODO ficitious play/focus punch
game: |
  Any set of circumstances that has a result dependent on the actions of two or more decision-makers
  ([players](#player)). In the context of competitive Pokémon battling, the "game" or "battle" can
  either be viewed as the combination of the [team-building](#piloting) _and_ [piloting](#piloting)
  components (and sometimes even featuring an initial [drafting](#drafting) component) or simply the
  piloting aspect. In most cases, without additional qualifiers the "game" can usually be understood
  to exclusively refer to the piloting component.
game tree: |
  A graph representing all possible game [states](#state) within a [game](#game). The [complete game
  tree]{.dfn} for a game is the game tree starting at the initial state and containing all possible
  [moves](#action) from each state and is equivalent to the tree obtained from the [extensive-form
  game] representation). Given that is usually intractable to enumerate the entire game tree in
  Pokémon, AI agents usually search over a [partial game tree]{.dfn} which contains a subset of the
  nodes from the complete game tree.
generation: |
  A grouping of Pokemon game releases that seperates them based on the Pokémon and mechanics they
  include. Generations are typically referred to by acronyms based on their release titles:

    - _Generation I_: RBY, RB
    - _Generation II_: GSC, GS
    - _Generation III_: ADV, RSE, RS, RSEFRLG
    - _Generation IV_: DPP, DPPt, HGSS, DPPtHGSS, DP
    - _Generation V_: BW, B2W2
    - _Generation VI_: XY, ORAS
    - _Generation VII_: SM, USUM
    - _Generation VIII_: SS, SwSh
    - _Generation IX_: SV
genetic algorithm: |
  Genetic algorithms ([GA]{.dfn}) are a method for solving both constrained and unconstrained
  optimization problems that is based on [natural
  selection](https://en.wikipedia.org/wiki/Natural_selection). Genetic algorithms are typically
  useful when the objective function is discontinuous, nondifferentiable, [stochastic](#stochastic),
  or highly nonlinear, and are often used to determine the values of
  [hyperparameters](#hyperparameter).
GF: |
  [Game Freak](https://www.gamefreak.co.jp/), primary developer and co-owner of Pokémon, responsible
  for the [cartridge](#cartridge) implementation.
gimmick: TODO
Glicko: |
  The Glicko rating system, a method used by [Pokémon Showdown!](#PS) to assess a player's strength.
  Used primarily for [usage stats](#usage-stats).
GXE: |
  [Glicko X-Act Estimate or "GLIXARE"](https://www.smogon.com/forums/threads/51169/), an estimate
  used by [Pokémon Showdown!](#PS) of a player's win chance against an "average" player.
HCE: |
  Hand-crafted evaluation --- a [evaluation function](#value) written manually (as opposed to
  learned), often leveraging [heuristics](#heuristic) or other [rule-based](#rule-based) approaches.
heuristic: |
  An approach for arriving at a solution by trial and error or by [rules](#rule) that are only
  loosely defined via methods which are not optimal, perfect, or rational, but is nevertheless
  sufficient for reaching an immediate, short-term goal or approximation.
hyperparameter: |
  A hyperparameter is a parameter whose value is used to control the learning process. By contrast,
  the values of other parameters (typically node weights) are derived via training.
inference: TODO deduction
information set: TODO ([IS]{.dfn})
information: TODO perfect vs. imperfect vs. hidden, complete vs. incomplete
input log: TODO <https://gist.github.com/scheibo/6d1473952f4c2b3852339f6f35301b93>
interior equilibra: TODO
joint actions: TODO
killer move: TODO
knowledge: TODO
Lc0: |
  [Leela Chess Zero (lc0)](https://lczero.org/), an open source computer chess agent based on the
  design behind [AlphaGo](#AlphaGo). Regularly competes with
  [Stockfish](https://stockfishchess.org/) for the title of strongest computer chess agent.
learning: |
  Learning refers to machine learning ([ML]{.dfn}), where statistical algorithms are leveraged to
  generalize and perform tasks without explicit instructions. There three main categories of
  machine learning are:

  1. Supervised learning, where both example inputs and their desired outputs are provided
  2. Unsupervised learning, only the inputs are provided, and
  3. [Reinforcement learning](#RL), where an agent aims to perform a certain goal and is given
  feedback along the way that it attempts to maximize
Libratus:
  The first computer agent to acheive superhuman performance in [no-limit Texas hold 'em
  poker](https://en.wikipedia.org/wiki/Go_(game)), using a new variant of [counterfactual regret
  minimization](#CFR) dubbed CFR+ [(Brown 2017)](/research#Brown:2017){.subtle}. Libratus was later
  followed by Modicum [(Brown 2018)](/research#Brown:2018){.subtle}, Pluribus [(Brown
  2019)](/research#Brown:2019){.subtle}, and ReBeL [(Brown 2020)](/research#Brown:2020){.subtle} ---
  state of the art agents which are similarly foundational as [AlphaGo](#AlphaGo) but for imperfect
  information games.
linear programming: |
  Linear programming ([LP]{.dfn}), also called linear optimization, is a method to achieve the best
  outcome (such as maximum profit or lowest cost) in a mathematical model whose requirements are
  represented by linear relationships. Typically used in competitive Pokémon AI research to solve
  for the [Nash equilbrium](#NE).
look ahead: |
  The [depth] that a search algorithm searches to.
LOS: |
  The likelihood of superiority denotes how likely it would be for two players of the same strength
  to reach a certain result --- in other fields called a p-value, a measure of statistical
  significance of a departure from the null hypothesis.
lrsnash: |
  A linear programming algorithm for determining all of the possible [Nash equilibrium](#NE)
  solutions in a [bimatrix game](#bimatrix-game) published in [(Avis
  2010)](/research#Avis:2010){.subtle} and available in the
  [`lrslib`](https://cgm.cs.mcgill.ca/~avis/C/lrs.html).
match-up: TODO MU
matrix node: TODO
MDP: |
  A [Markov decision process]{.dfn} is as a [stochastic](#stochastic) decision-making process that
  uses a mathematical framework to model the decision-making of a dynamic system in scenarios where
  the results are either random or controlled by a decision maker, which makes sequential decisions
  over time. In competitive Pokémon AI reseach, "MDP" may also refer to the [MaxDamagePlayer] in
  certain contexts.
MaxDamagePlayer: TODO MDP, MostDamage, OTL, base power
MCTS: TODO
metagame: TODO
metaheuristic: TODO <https://en.wikipedia.org/wiki/Metaheuristic>
midgame: TODO
minimax: TODO
move: TODO
MVP: TODO
NE: TODO nash equilibrium
NN: |
  A [neural network]{.dfn}, is a computer system modeled on the human brain and nervous system,
  comprised of multiple layers of "nodes", containing an input layer, one or more hidden layer, and
  an output layer. Each node, or artificial neuron, connects to another and has an associated weight
  and threshold. If the output of any individual node is above the specified threshold value, that
  node is activated, sending data to the next layer of the network. Otherwise, no data is passed
  along to the next layer of the network.
NNUE: |
  An [efficiently updatable [neural network](#NN)]{.dfn}, stylized "ƎUИИ", an architecture intended
  to replace the [evaluation function](#value) of [alpha-beta](#Alpha-beta) searches running on a
  CPU via [SIMD](#SIMD) instructions. [Originally developed for Computer
  Shogi](https://github.com/asdfjkl/nnue/blob/main/nnue_en.pdf), NNUE has been used successfully in
  chess engines such as [Stockfish](https://stockfishchess.org/) to acheive high ratings.
observation: |
  Information produced when the [state](#state) [transitions](#transition). In Pokémon this may
  include a result which can be used to determine [payoff](#payoff) and possibile legal
  [actions](#action), "logs" which detail various events that may have occured, an account of the
  [chance](#chance) actions, or a multitude of other possibilities depending on the
  [engine](#engine).
offline: |
  An offline algorithm is given the whole problem data from the beginning and is required to output
  an answer which solves the problem at hand. If something can be done "offline" that usually means
  that it can be precomputed ahead-of-time, as opposed to in the middle of a game (contrast to
  [online](#online)).
online: |
   An online algorithm is one that can process its input piece-by-piece in a serial fashion, _i.e._,
   in the order that the input is fed to the algorithm, without having the entire input available
   from the start (in contrast to [offline](#offline)).
opponent modeling: TODO
OTL: |
  One-[turn](#turn) [look ahead](#look-ahead). The [MaxDamagePlayer] is the conventional name for an
  agent which leverages only a single turn of look ahead.  "$`N`TL" can be used to generalize this
  shorthand for describing the depth an agent searches to, _e.g._, "3TL" for three turns worth of
  look ahead.
pathology: |
  Game-tree pathology is a phenomenon where searching a game-tree deeper gives results in worse
  decision.
payoff: |
  The reward a player receives from arriving at a particular outcome. In Pokémon, only terminal
  states give rewards, where the reward is determined based on the result of the battle (winning,
  losing or drawing --- though pedantically, Pokémon glitches mean that one also needs to support
  the notion of a battle ending in "error" which can usually be mapped to a draw) and the
  utility/reward function (which will usually map [W/L/T](#WLT) to `1/-1/0` making Pokémon a
  [zero-sum](#zero-sum) game or `1/0/0.5` making Pokémon a [constant-sum](#zero-sum) game, the
  latter being more common).
PBS: TODO public belief state
perspective: TODO viewpoint (spectator/omniscient/player)
piloting: |
  The component of competitive Pokémon that involves playing out a battle [online](#online) _after_
  each players' teams have already been chosen.
pkmn: |
  A common abbreviation of Pokémon dating back to the earliest releases where the stylized
  ^P^~K~^M^~N~ was included in the [cartridge](#cartridge) character set. However, this abbreviation
  has since been adopted as the name for the [pkmn](https://pkmn.cc) collection of projects (notably
  the pkmn [engine](#engine), [`libpkmn`](https://pkmn.cc/engine)) and is often what is being
  referenced (and is always what is being referred to when prefixed with an "@", as @pkmn is the
  name of the [organization](https://github.com/pkmn)).
player: |
  A strategic decision-maker within the context of the game. In Pokémon these are usually referred
  to as "Player 1" and "Player 2" (alternatively, "P1"/"P2" or "Player A"/"Player B") and are
  technically not completely [symmetrical](#symmetry) because certain game mechanics depend on the
  notion of the "host" player (conventionally P1). In more general terms, either P1 or P2 may be
  considered the "player" vs. the "enemy" / "foe" depending on [perspective](#perspective) --- the
  P1 vs. P2 distinction is absolute whereas the less specific player vs. foe terminology is
  relative. When considering Pokémon as a [bimatrix game](#bimatrix-game) the "row player" and
  "column player" are usually also used to refer to relative perspectives.
playout: TODO
PoG:
  Player of Games, the original name of the general game-playing agent from [(Schmid
  2021)](/research#Schmid:2021){.subtle} which utilizes improved counterfactual regret minimizaton
  to acheive superhuman performance in a variety of games.
policy: |
  A policy is a [state](#state) to [action](#action) mapping --- for each action possible from a
  given state, a policy returns the probability of taking the action. Ultimately, the objective of a
  competitive Pokémon AI is to determine the optimal policy for any given state. [Reinforcement
  learning](#RL) aims to accomplish this by learning a [policy network]{.dfn}.
POMDP: |
  Partially observable Markov decision process, a generalization of a [Markov decision
  process](#MDP) which models an agent decision process in which it is assumed that the system
  dynamics are determined by an MDP, but the agent cannot directly observe the underlying
  [state](#state).
pondering: |
  The act of thinking during an opponent's turn. Given that Pokémon is a [simultaneous move](#SM)
  game, pondering occurs after a player has submitted their action (or been asked to wait) while
  they are waiting for their next opportunity to input an action.
prediction: TODO
protocol: TODO
pruning: TODO
PS: |
  [Pokémon Showdown!](https://pokemonshowdown.com), the most popular and influential Pokemon battle
  [simulator](#sim).
Q-learning: |
  A model-free [reinforcement learning](#RL) algorithm to learn the value of an [action](#action) in
  a particular [state](#state) that can handle problems with [stochastic](#stochastic)
  [transitions](#transition) and [rewards](#payoff) without requiring adaptations. Q-learning was
  used by DeepMind in their Deep Q-Network ([DQN]{.dfn}) algorithm  along with a technique called
  experience replay to solve a wide-range of Atari games [(Mnih
  2015)](/research#Mnih:2015){.subtle}.
RandomPlayer: |
  TODO RPs includes switching or not, RandomPlayer(`N`) can mean how often
  consider switches vs. how often ONLY consider switching when option prefer
  what % actually chooses switch as opposed to % actually considers switch. also
  extend to RP(M, N) where second value is *gimmick* (use mega/z
  move/dynamax/tera). **choose** vs. **consider** (add some icon like an icon on
  top of number to indicate consider?) $`RP(\widetilde{20\%}, 90\%)` means
  *consider* switch 20% of the time and use zmove when available 90% of the
  time.
regret: TODO
relaxation: TODO
reverse damage calculator: TODO
RL: |
  Reinforcement learning is form of [machine learning](#learning) where an [agent](#agent) learns
  to take actions to maximize a cumulative reward.
roll: TODO
rollout: TODO
rule-based: |
  A system that applies human-made [rules](#rule) to store, sort and manipulate data as opposed to
  rules discovered via machine [learning](#learning). These systems typically take the forum of
  `if-then` statements and involve [hand-crafted evaluation](#HCE) functions.
rule: TODO PS custom "rule" vs. rules-ased
search: TODO
self-play: TODO
sequentialization: TODO serialization
server: |
  Where the game [engine](#engine) is being run and where the actual, complete battle
  [state](#state) is stored. The server is responsible for keeping relevant information hidden from
  the [client](#client).
sim: TODO simulator
SIMD: |
  SIMD is short for Single Instruction on Multiple Data, which are a type of CPU instruction which
  allows for computing operations in parallel on a vector of numbers.
simplification: TODO
simultaneous: TODO
slot: TODO
SM: TODO AM, compare to sequential, sun moon (generation)
Smogon: |
  [Smogon University](https://smogon.com), home of competitive Pokémon battling and curator of rules
  and restrictions for the most popular competitive [formats](#format) outside of those supported by
  Nintendo.
sparse: TODO
STAB: |
  An abbreviation for same-type attack bonus, a mechanic where a damage boost that is applied to
  moves used by a Pokémon of the same type.
state: |
  The information required to determine which [actions]#(action) are available to each
  [player](#player). In Pokémon, this is the *battle*, and the term "battle" is used as opposed to
  "state" as "state" is a loaded term in programming (programming in general is arguably all about
  the management of state, so "state" needs to be qualified as "battle state" or "game state" to be
  unambigious) despite it being a useful term in papers dealing purely with theory.
stochastic: TODO probabilistic vs. non-deterministic
strategy: TODO
subgame: TODO
symmetry: TODO
TD-learning: |
  [Temporal difference learning]{.dfn} refers to a class of model-free [reinforcement learning](#RL)
  methods which learn by bootstrapping from the current estimate of the [value function](#value).
  These methods sample from the environment and perform updates based on current estimates,
  adjusting predictions to match later, more accurate, predictions about the future before the final
  outcome is known.
Team Preview: |
  A pre-battle phase introduced in [Generation V](#generation) in which players get to see each of
  the Pokémon on their opponent's team and choose which Pokémon get brought to battle and in which
  order.
team-building: |
  The component of competitive Pokémon that involves constructing a team [offline](#offline) before
  a battle, usually with the aim of being able to beat the entire [metagame](#metagame).
Thompson sampling: TODO
Torch: |
  The defacto standard open source machine learning and scientific computing framework, most often
  used in Python via [PyTorch](https://en.wikipedia.org/wiki/PyTorch).
TPCi: |
  [The Pokémon Company International](https://corporate.pokemon.com/), co-owners of the Pokémon
  franchise along with the publisher and trademark-holder, Nintendo, and the developers, [Game
  Freak](#GF).
transformer: TODO
transition: |
  The change that a [state](#state) undergoes due to an [action](#action). In the [pkmn](#pkmn)
  engine, this is implemented by a a battle's `update` function. In game theory, "turns" are
  typically count transitions (though [not in Pokémon](#turn)), and a transition may produce a
  [payoff](#payoff) or some sort of [observation](#observation).
transitions: TODO engine nomenclature
transposition: TODO
TBS: |
  [Tree-bandit search]{.dfn}, the name for the family of search algorithms which are roughly based
  around [Monte-carlo tree search](#MCTS) but which make use of various [bandit](#bandit) algorithms
  to greatly improve performance and convergence.
tuning: TODO
turn: |
  Game theory uses the term [ply]{.dfn} to refer to one turn taken by one player in a
  [sequential](#SM) game which doesn't apply to Pokémon given that Pokémon is a [simultaneous](#SM)
  game. A "turn" in Pokémon is a well-defined concept as certain game mechanics depend on its
  definition (_e.g._, residual damage happens at the end of a turn in Pokémon in later generations).
  Instead, it is more useful to in terms of [decision point]{.dfn} that occur between _updates_ to
  the battle state (which may happen multiple times in a single turn, _e.g._, due to a Pokémon using
  Baton Pass or fainting) --- places where the game requires input from players to proceed. In
  [Pokémon Showdown!](#PS) and the [pkmn](#pkmn) engine, a decision point always requires a [joint
  action](#action), introducing the concept of "passing"/"waiting" to account for situations where
  on a console one of the players is forced to do nothing while input is collected from their
  opponent.
UCB: |
  Upper Confidence Bound, a [bandit](#bandit) algorithm commonly used in [tree
  bandit search](#TBS).
UCT: |
  Upper Confidence bounds applied to Trees, the contemporary standard implementation of [Monte-carlo
  tree search](#MCTS) which uses the [UCB](#UCB) algorithm to select promising child nodes to
  expand. See also [tree bandit search](#TBS).
uniform policy: |
  A [policy](#policy) which assigns equal (uniform) probability to each of the actions possible ---
  this sort of policy is usually only optimal in the absence of any other information (_e.g._, at
  the beginning of a search).
usage stats: |
  Statistics processed from a corpus of battle logs that detail the usage of various Pokémon and
  their attributes for a given format. [Smogon University](#Smogon) produces [public
  statistics](https://www.smogon.com/stats/) calculated from all rated battles on [Pokémon
  Showdown!](#PS) each month which they use to influence the tiering decisions for the
  [formats](#format) they maintain, though alternative usage statistics can also be produced for
  specific use cases.
value: |
  The expected [payoff](#payoff) from a given [state](#state), produced by an [evaluation
  function]{.dfn}. Evaluation functions are usually difficult to produce accurately in Pokémon and
  are often approximated with [reinforcement learning](#RL) via  a [value network]{.dfn} in that
  assigns a value to each state of the game by calculating an expected cumulative score.
vaporware: |
  Software that has been advertised but is not yet available to use/buy, either because it is only a
  concept or because it is still being written or designed. See also [pkmn](#pkmn).
variant: |
  A variation from the standard rules of competitive Pokémon which usually simplifies/relaxes
  certain properties/rules of the game to make it more tractable for AI, with the expectation that
  solutions to a variant will usually be useful for generalizing to the original ruleset. In
  computer poker, "[Kuhn poker](https://en.wikipedia.org/wiki/Kuhn_poker)" is the most common
  simplification studied, whereas in Pokémon there are [numerous potential options of
  variants](/concepts/variants). Note that while the various Pokémon [formats](#format) can be
  considered variants, the term "variant" is reserved to describe simplifications to the game that
  go beyond the rule changes typical between formats.
WLT: |
  WLT or W/L/T refers to win, loss and tie (draw) record of a particular [player](#player) or
  [agent](#agent).
wincon: |
  A [win condition]{.dfn} is a Pokémon or scenario that a player needs in order to secure that they
  win the game.
zero-sum: TODO constant-sum